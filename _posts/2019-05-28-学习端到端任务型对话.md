---
layout: post
title:  "端到端任务型对话系统"
categories: 论文
tags:  任务型对话 对话策略
author: littleRound
comment: true
excerpt: 本文提出端到端任务型对话，创建了新的任务（阶段分解）和数据集使用方式，用Memory Network跑了一下，并和搭建的baseline进行了对比。
---

* content
{:toc}

{% raw %}

# 学习端到端任务型对话

论文原文链接：[Learning End-to-End Goal-Oriented Dialog](https://arxiv.org/abs/1605.07683)

> ICLR2017 - Facebook

## 摘要

相比于传统的[任务型对话系统](https://littleround.cn/2019/01/19/%E5%BD%93%E4%BD%A0%E6%89%93%E6%B5%B7%E5%BA%95%E6%8D%9E%E5%AE%A2%E6%9C%8D%E7%9A%84%E6%97%B6%E5%80%99-%E8%B0%88%E8%B0%88%E4%BB%BB%E5%8A%A1%E5%9E%8B%E8%AF%AD%E9%9F%B3%E5%AF%B9%E8%AF%9D/)，提出端到端任务型对话主要有**2点原因**：

1. 传统系统需要对**每个对话领域**进行领域相关的**手动**构造，**扩充领域时会很麻烦**；而端到端任务型对话通过**直接学习对话本身**，解除了这一限制。
2. 在**闲聊型**对话（chit-chat）中，**端到端~~闲聊~~对话系统**有着**不错**的表现。

本文主要的亮点是：

1. 提出一个测试框架：如何**利用对话数据**、如何设置**子目标**进行**评估**等等。
2. 提出一种参考解决方案——**Memory Network**。文中宣称该网络可以学习非平凡的修改句子符号的能力。

## 引言

- **传统**任务型对话系统
  - 市面上的**数字个人助手**。
  - 方法：定义**对话槽**并填槽（slot filling）。
- **闲聊型**（chit-chat）端到端对话系统
  - 通过**直接学习对话数据**，**不假定对话领域**从而**自动适应**对话中出现的领域。
  - 数据来源：社交媒体、论坛讨论、电影对白。
  - 直接套用到任务型对话时出现的**问题**：
    - **目的**不明确，几乎无法明确做事（无法确定订餐馆等实际目的）
    - 性能定义很模糊（**评估**方式本身有争议，较主观）
- 本文工作：
  - 提出一个轻量、易用、开放、可比较、可复现的端到端对话系统测试方法。
  - 具体方法：将完成任务型对话的过程划分为几个阶段——几个子任务，每个阶段显示系统的一些**能力指标**，即**管理对话**、**查询知识库**（数据库）、**解释知识库返回的结果**，处理训练中**未见过**的新的实体。
  - 评估准则：单句准确率（单句返回是否与原始数据相同）或对话准确率（该阶段的全部涉及单句是否**全部正确**）。
  - 数据来源：
    - Task1 - Task5：模拟数据（通过数据库生成）
    - Task6：DSTC（对话状态追踪挑战，数据有改动）
    - Task7：Concierge（收集来的真实数据）
  - 结果：
    - 超越slot-filling和rule-based基线系统
    - 单句准确率还好，对话准确率很低

## 相关工作

1. POMDP
   - 存在问题：要**手造**对话状态特征和对话动作。
   - 本文对比：本文通过数据集训练端到端，类似于用[用户模拟器](https://littleround.cn/2019/03/11/%E4%B8%BA%E4%BB%BB%E5%8A%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E6%A8%A1%E6%8B%9F%E5%99%A8/)训练分模块。
2. 数据与数据集
   - 存在问题：之前的基本都是用于训练对话状态追踪（DST）的，没有适合端到端的。
   - 本文对比：改了DSTC的数据集格式，通过数据集评测使其有可复现性。
3. 智能问答系统
   - 自然语言处理（NLP）中的问题回答（QA）任务中有使用本文类似的技术。
   - ~~同样使用Memory Network的 [Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems](https://arxiv.org/abs/1511.06931) 这篇和本文较为相似，区别是其更关注回答事实问题。~~

## 本文中的任务型对话

### Task1 - Task5：通过知识库生成

![t1-t5](static/post_resource/2019-05-28-1.png)

- 通过数据库中的餐馆实例（风味、价格、评级、人数等等），模拟订餐过程
- 数据库通过API询问，输入条件输出餐馆列表
- 采样生成请求，模版生成话语（43个用户模版，20个机器人模版）
- **阶段定义**~~（本文核心内容）~~：
  - 阶段1-2学对话状态追踪（DST）；
  - 阶段3-4学数据库使用（其中阶段3还要学排序）；
  - 阶段5是完整对话结合起来。

| 阶段             | 内容                                                       |
| ---------------- | ---------------------------------------------------------- |
| 1- 提出API调用   | 机器人按照**特定顺序**询问缺少的域                         |
| 2 - 更新API调用  | 根据用户的问题调整调用参数，直到用户满意并进行调用         |
| 3 - 展示选项     | 按特定打分顺序向用户展示查询结果，如果用户不满意就换一个。 |
| 4 - 提供额外信息 | 如果用户决定预定（该餐馆），则提供电话号、地址等信息。     |
| 5 - 整合整个对话 | 前4个任务全完成一遍构成对话。                              |

- 阶段划分**细节**上：    
  - 阶段3中：查询结果会加入当前对话状态，只保留返回多于2个查询结果的模拟且设定上用户最后总会满意，
  - 阶段4中：所预定的餐馆的相应信息会加入当前对话状态。
  - 阶段5中：一点小区别是任务3上的只保留大于2个查询结果变成只保留大于0。

- 数据集划分~~（实现处理训练中**未见过**的新的实体的能力评估）~~：
  - 关于如何划分训练、开发、测试集：为了测试出现在知识库中但没出现在训练中的实体（即餐馆），**划分了2个知识库**。
    - 一个用来生成训练集（train）、开发集（dev）、测试集（test）。
    - 另一个**只生成测试集**（test），称为OOV（out-of-vocabulary）测试集。
  - 划分的时候**共享**了一部分评分、价格这种非餐馆相关的知识库数据。
  - 训练时**用合并的知识库**响应API调用。
  - 五个阶段各生成一个数据集，分别为Task1到Task5。
  - 注意任务并**不要求**神经网络**生成**API调用，而是给所有数据集中可能出现的API进行**排序**~~（，生成问题转换为排序问题）~~。

### Task6：改造后的DSTC

- 文章用了这个数据集作为第六类任务。
- 由于修改了一部分，本文无法和别的使用相同数据集的工作比较。
- 转化出来的任务比Task1-Task5的模拟稍难一点（规则稍有不同）。

### Task7：线上礼宾服务 Concierge

- 上述六类任务均为人工构造，**缺乏真实性**。
- **引进**在线订餐产生的4k次**真实数据**（其中扮演机器人的人类进行API调用），作为第七类任务。
- 数据经过清洗脱敏，并且不包含API调用的结果，但记录了API调用行为本身。
- 数据**特点**：
  - 对话更短
  - 词汇更丰富
  - 询问不规则
  - 可能询问数据库外数据
  - 存在语法、拼写错误等噪声

## 模型

1. 规则系统模型

   - 对于构造的数据确实很强100%成功~~（辩解：不是为了确认人能不能做出rule-based，而是用来分析神经网络能多聪明）~~。
   - 对于第六类任务Task6（DSTC数据）因为太复杂了所以我们搭建了28条规则，分析21种模式，让回复正确率达到了40.7%。而Concierge上搭都没搭（因为限制更少，太复杂）。

2. 经典信息提取（IR）模型

   - 不使用机器学习方法~~（和闲聊系统常规做法对比）~~。
   - **TF-IDF匹配**：通过TF-IDF加权的词袋cos相似度来比较上一个对话/整个对话历史~~（试了一下后者更好用，所以就用了后者）~~。
   - **最近邻匹配**：找到训练集里最相近的（字重叠率作为打分），使用找到的训练中的回复。

3. 监督学习的嵌入模型

   - 使用**词嵌入向量**，监督学习给排序做打分。
   - 使用Margin ranking loss（采样负例，正例比负例大一个margin）。

4. 记忆网络（Memory Network）模型

   - NLP**常见方法**（问答、语言模型，闲聊系统）
   - 有时比基于RNN的方法厉害
   - MemN2N架构（直观上是模拟指针，有空单独写一篇），**对精确匹配做了改进**

5. 引入**新特征**：对待实体时类型匹配特征- match type feature

   - 由词定义的实体（餐馆）的两个特点：精确匹配比模糊匹配更容易应对；经常出现OOV。这两个特点对基于词嵌入的方法是个挑战。
   - 挑战：精确匹配和极相似语义不好区分；对OOV无力。
   - match type feature：将7种类型的具体词**根据规则用tag代替**。

## 实验

- 实验结果[见表](https://arxiv.org/pdf/1605.07683.pdf#page=8&zoom=100,0,117)。
- 解释TF-IDF在闲聊型好用，而任务型不好：
  - 因为**对话流程进行更快**~~（话说的更有方向性和目的性）~~，更少的相似词
- 基于监督学习的嵌入模型表现还好但不够好，不能成功完成对话。
- MemoryNetwork性能好不少，提出的原因是其可以进行**连续访问与归因**。
- 类型匹配特征（match type feature）很好用，**可以解决部分匹配问题**（精确匹配问题），但不是万全法。
- 本文使用的方法有改进，但还**未完全解决问题**。对于真实数据能有一定直接提升，但效果依然不好，只能算有借鉴意义。

## 总结

- 本文提出端到端任务型对话。
- 本文创建了新的任务（阶段分解）和数据集。
- 本文用Memory Network跑了一下，并和搭建的baseline进行了对比。



{% endraw %}